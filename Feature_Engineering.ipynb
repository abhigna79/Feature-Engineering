{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mt6ykqPwRuJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "dqO9nvz9wbaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "   - A parameter is a value that is passed into a function, method, or procedure to customize its behavior. Parameters act as variables inside the function and are used to accept input from the caller.\n",
        "\n",
        "2. What is correlation?\n",
        "   - Correlation is a statistical measure that describes the relationship between two variables. It tells us whether and how strongly two variables are related.\n",
        "\n",
        "   - What does negative correlation mean?\n",
        "   - Negative correlation means that as one variable increases, the other variable decreases. In other words, they move in opposite directions.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "   - Machine Learning is a branch of artificial intelligence (AI) that enables systems to learn from data and make predictions or decisions without being explicitly programmed. Instead of following strict rules, ML algorithms improve their performance over time by recognizing patterns in data.\n",
        "\n",
        "   - Main Components of Machine Learning:\n",
        "   - Data\n",
        "   - Features (Input Variables)\n",
        "   - Model\n",
        "   - Training\n",
        "   - Evaluation (Testing & Validation)\n",
        "   - Hyperparameters & Optimization\n",
        "   -  Deployment\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "   - The loss value is a numerical measure of how well (or poorly) a machine learning model is performing. It quantifies the difference between the model’s predicted output and the actual target values. Lower loss values indicate a better model, while higher loss values suggest poor performance.\n",
        "\n",
        "   - How Loss Helps in Evaluating a Model:\n",
        "   - Measures Prediction Accuracy\n",
        "   - Guides Model Optimization\n",
        "   - Prevents Overfitting or Underfitting\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "   - In data analysis and machine learning, variables are classified into two main types: continuous and categorical variables.\n",
        "\n",
        "   - Continuous Variables:\n",
        "   - A continuous variable can take an infinite number of values within a given range. These values are usually numerical and can be measured rather than counted.\n",
        "   - Categorical Variables:\n",
        "   - A categorical variable represents distinct groups or categories. These variables are usually non-numeric (but can be represented numerically, like 0 or 1) and are typically countable.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common  teachniques?\n",
        "   - Since most machine learning models work with numerical data, categorical variables must be converted into a numerical format before training.\n",
        "   \n",
        "   -  The common  teachniques are:\n",
        "   - Encoding Categorical Variables\n",
        "   - Label Encoding\n",
        "   - Ordinal Encoding\n",
        "   - Target Encoding (Mean Encoding)\n",
        "   - Hashing Encoding.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "   - In machine learning, we split a dataset into two main parts: training and testing datasets. This helps evaluate how well a model can generalize to unseen data.\n",
        "\n",
        "   - Training Dataset:\n",
        "   - The training dataset is used to train the machine learning model.\n",
        "\n",
        "   - The model learns patterns from the input data by adjusting its internal parameters.\n",
        "\n",
        "   - Usually makes up 70-80% of the total dataset.\n",
        "\n",
        "   - Testing Dataset:\n",
        "   - The testing dataset is used to evaluate the trained model.\n",
        "\n",
        "  - It contains new data that the model has never seen before to check its performance.\n",
        "\n",
        "   - Usually makes up 20-30% of the total dataset.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a module in Scikit-Learn that provides various techniques for scaling, encoding, and transforming data to prepare it for machine learning models.\n",
        "\n",
        "9. What is a Test set?\n",
        "   - A test set is a portion of the dataset used to evaluate the performance of a trained machine learning model. It contains new data that the model has never seen before to check how well it generalizes to unseen data.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "    - To train and evaluate a machine learning model, we need to split our dataset into:\n",
        "    - Training Set → Used to train the model (typically 70-80% of data).\n",
        "    - Test Set → Used to evaluate the model (typically 20-30% of data).\n",
        "\n",
        "    -  How do you approach a Machine Learning problem?\n",
        "    - Solving a machine learning (ML) problem involves systematic steps:\n",
        "    - Understand the Problem\n",
        "    - Collect and Explore Data (EDA - Exploratory Data Analysis)\n",
        "    - Data Preprocessing & Feature Engineering\n",
        "    - Split Data for Training & Testing\n",
        "    - Choose and Train a Model\n",
        "    -  Evaluate Model Performance\n",
        "    - Hyperparameter Tuning & Model Optimization\n",
        "    - Deploy the Model\n",
        "    - Monitor and Improve\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "    - Exploratory Data Analysis (EDA) is critical before fitting a model because it helps you understand your data, detect issues, and make informed preprocessing decisions. Skipping EDA can lead to poor model performance, misleading results, and overfitting.\n",
        "\n",
        "12. What is correlation?\n",
        "    - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. It helps us understand how one variable changes in relation to another.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "    - A negative correlation means that as one variable increases, the other decreases. In other words, they move in opposite directions.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "    - Python provides several ways to compute the correlation between variables, most commonly using Pandas and NumPy.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example?\n",
        "    - Causation (also called cause-and-effect) means that one variable directly influences another. If A causes B, then changing A will directly lead to a change in B.\n",
        "\n",
        "    - Correlation:\n",
        "    - A relationship between two variables\n",
        "    - EX:Ice cream sales ↑ & Drowning deaths ↑ (but summer causes both)\n",
        "\n",
        "    - causation:\n",
        "    - Causation (also called cause-and-effect) means that one variable directly influences another. If A causes B, then changing A will directly lead to a change in B.\n",
        "    - EX:Studying more → Higher grades\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example?\n",
        "    - An optimizer is an algorithm used in Machine Learning and Deep Learning to adjust model parameters (weights and biases) to minimize the loss function. The goal of an optimizer is to improve model performance by reducing errors.\n",
        "\n",
        "    - Types of Optimizers in Machine Learning:\n",
        "    -  Gradient Descent (GD)\n",
        "    - Stochastic Gradient Descent (SGD)\n",
        "  -  Mini-Batch Gradient Descent\n",
        "  - Momentum\n",
        "   - AdaGrad (Adaptive Gradient Algorithm)\n",
        "   -  RMSprop (Root Mean Square Propagation)\n",
        "  -  Adam (Adaptive Moment Estimation)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "W-KSdmsyw292"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent (GD):EXAMPLE"
      ],
      "metadata": {
        "id": "JXhEII8z40Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cost function: f(x) = x^2\n",
        "def cost_function(x):\n",
        "    return x**2\n",
        "\n",
        "# Gradient: f'(x) = 2x\n",
        "def gradient(x):\n",
        "    return 2*x\n",
        "\n",
        "# Gradient Descent Algorithm\n",
        "x = 10  # Initial point\n",
        "learning_rate = 0.1\n",
        "for i in range(10):  # 10 iterations\n",
        "    x = x - learning_rate * gradient(x)\n",
        "    print(f\"Iteration {i+1}: x = {x}, Cost = {cost_function(x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qliYYDRC4F5F",
        "outputId": "80c2fb7a-08ad-497c-ba46-8aed7ec34758"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: x = 8.0, Cost = 64.0\n",
            "Iteration 2: x = 6.4, Cost = 40.96000000000001\n",
            "Iteration 3: x = 5.12, Cost = 26.2144\n",
            "Iteration 4: x = 4.096, Cost = 16.777216\n",
            "Iteration 5: x = 3.2768, Cost = 10.73741824\n",
            "Iteration 6: x = 2.62144, Cost = 6.871947673600001\n",
            "Iteration 7: x = 2.0971520000000003, Cost = 4.398046511104002\n",
            "Iteration 8: x = 1.6777216000000004, Cost = 2.8147497671065613\n",
            "Iteration 9: x = 1.3421772800000003, Cost = 1.801439850948199\n",
            "Iteration 10: x = 1.0737418240000003, Cost = 1.1529215046068475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient Descent (SGD):\n",
        "EXAMPLE"
      ],
      "metadata": {
        "id": "obcwad2l4O4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Example data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 6, 8, 10])  # y = 2x\n",
        "\n",
        "# SGD Model\n",
        "sgd = SGDRegressor(learning_rate=\"constant\", eta0=0.1, max_iter=1000)\n",
        "sgd.fit(X, y)\n",
        "\n",
        "print(f\"Weight: {sgd.coef_}, Bias: {sgd.intercept_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcQ_wYbT4U1h",
        "outputId": "acbe7e78-5c2f-4713-83a2-f8df48a0828b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight: [1.90349378], Bias: [0.2170783]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mini-Batch Gradient Descent:\n",
        "\n",
        "EXAMPLE:Used in Deep Learning frameworks like TensorFlow & PyTorch.\n",
        "\n",
        "Momentum Optimization:\n",
        "\n",
        "EXAMPLE:Used in deep learning (Keras, PyTorch, TensorFlow).\n",
        "\n",
        "RMSprop (Root Mean Square Propagation):\n",
        "\n",
        "EXAMPLE:Used in TensorFlow, Keras.\n",
        "\n",
        "Adam (Adaptive Moment Estimation):EXAMPLE\n",
        "\n"
      ],
      "metadata": {
        "id": "KQ_XjzMw48eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n"
      ],
      "metadata": {
        "id": "9gvVVXQQ57y4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "    - sklearn.linear_model is a module in Scikit-Learn that provides various linear models for regression and classification tasks. It includes algorithms like Linear Regression, Logistic Regression, Ridge, Lasso, and more.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "    - In Scikit-Learn, model.fit() is used to train a machine learning model on a given dataset. It learns the patterns from the training data and updates the model's internal parameters (e.g., weights in linear regression, decision tree splits, etc.)\n",
        "\n",
        "    - Arguments Required for fit()\n",
        "    -  Optional Parameters for fit()\n",
        "    - When NOT to Use fit()\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "    - model.predict() is used to make predictions after a machine learning model has been trained with model.fit(). It takes new input data and returns the model’s predicted outputs based on learned patterns.\n",
        "\n",
        "    -  Required Arguments for predict()\n",
        "    - How predict() Works Internally\n",
        "    - Common Errors in predict()\n",
        "    \n",
        "20. What are continuous and categorical variables?\n",
        "    - In machine learning and statistics, variables are classified into continuous and categorical based on the type of data they represent.\n",
        "\n",
        "   - Continuous Variables:\n",
        "   - These variables can take any numerical value within a range and can be measured (e.g., weight, height, temperature).\n",
        "   - Categorical Variables:\n",
        "   - These variables represent distinct groups or categories. They do not have a numerical meaning.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "    - Feature Scaling is a technique used in machine learning to normalize or standardize numerical features so that they are on the same scale. It ensures that no single feature dominates others due to differences in magnitude.\n",
        "\n",
        "  - How does it help in Machine Learning?\n",
        "  -  Improves Model Performance\n",
        "  - Speeds Up Training\n",
        "  - Prevents Some Features from Dominating\n",
        "  - Essential for Distance-Based Algorithms\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "    - Feature scaling can be done using Scikit-Learn. The two most common techniques are:\n",
        "   -  Min-Max Scaling (Normalization)\n",
        "    -  Standardization (Z-score Normalization)\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "    - sklearn.preprocessing is a module in Scikit-Learn that provides tools for feature transformation and scaling in Machine Learning. It helps in normalizing, encoding, and standardizing data to improve model performance.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "    - When building a Machine Learning model, we need to split the dataset into:\n",
        "    - Training Set → Used to train the model\n",
        "    - Test Set → Used to evaluate model performance\n",
        "\n",
        "25. Explain data encoding?\n",
        "    - Data Encoding is the process of converting categorical data (text or labels) into numerical form so that machine learning models can process it.\n",
        "\n"
      ],
      "metadata": {
        "id": "UzKEWBGo6HRH"
      }
    }
  ]
}